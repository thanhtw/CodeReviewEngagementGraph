#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å“è³ªæŒ‡æ¨™èˆ‡æˆç¸¾ç›¸é—œæ€§åˆ†æ
åˆ†æå­¸ç”Ÿè©•è«–å“è³ªæŒ‡æ¨™ï¼ˆç›¸é—œæ€§ã€å…·é«”æ€§ã€å»ºè¨­æ€§ï¼‰èˆ‡å­¸æœŸæˆç¸¾çš„é—œè¯æ€§
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rcParams
import json
import os

# ä½¿ç”¨ç•¶å‰è…³æœ¬æ‰€åœ¨ç›®éŒ„
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# è¨­å®šä¸­æ–‡å­—å‹
rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (10, 8)

def load_student_data():
    """è¼‰å…¥ä¸¦è™•ç†å­¸ç”Ÿå“è³ªæŒ‡æ¨™è³‡æ–™"""
    try:
        # è¼‰å…¥è™•ç†éçš„è³‡æ–™
        data_path = os.path.join(BASE_DIR, 'function', '3labeled_processed_totalData.json')
        with open(data_path, 'r', encoding='utf-8') as f:
            total_data = json.load(f)
        
        # æ•´ç†å­¸ç”Ÿè³‡æ–™
        student_metrics = {}
        
        if 'recordData' in total_data:
            record_data = total_data['recordData']
        else:
            record_data = total_data
            
        for hw_name, hw_data in record_data.items():
            if not isinstance(hw_data, list):
                continue
                
            for assignment in hw_data:
                if not isinstance(assignment, dict) or 'Reviewer_Name' not in assignment:
                    continue
                    
                reviewer = assignment['Reviewer_Name'].strip()
                
                if reviewer not in student_metrics:
                    student_metrics[reviewer] = {
                        'relevance_count': 0,
                        'concreteness_count': 0,
                        'constructive_count': 0,
                        'total_valid_rounds': 0,
                        'assignments': set()
                    }
                
                # çµ±è¨ˆæ¯å€‹ä½œæ¥­çš„å“è³ªæŒ‡æ¨™
                for round_key, round_data in assignment.items():
                    if round_key.startswith('Round') and isinstance(round_data, dict):
                        feedback = round_data.get('feedback_text', '').strip()
                        if feedback:  # æœ‰æ•ˆè©•è«–
                            student_metrics[reviewer]['total_valid_rounds'] += 1
                            student_metrics[reviewer]['assignments'].add(hw_name)
                            
                            # çµ±è¨ˆå“è³ªæŒ‡æ¨™
                            if round_data.get('Relevance') == 1:
                                student_metrics[reviewer]['relevance_count'] += 1
                            if round_data.get('Concreteness') == 1:
                                student_metrics[reviewer]['concreteness_count'] += 1
                            if round_data.get('Constructive') == 1:
                                student_metrics[reviewer]['constructive_count'] += 1
        
        return student_metrics
        
    except Exception as e:
        print(f"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {}

def generate_mock_scores(student_metrics):
    """æ ¹æ“šå“è³ªæŒ‡æ¨™ç”Ÿæˆæ¨¡æ“¬çš„æˆç¸¾è³‡æ–™"""
    np.random.seed(42)  # ç¢ºä¿çµæœå¯é‡ç¾
    
    scores_data = {}
    
    for student, metrics in student_metrics.items():
        if metrics['total_valid_rounds'] == 0:
            continue
            
        # è¨ˆç®—å“è³ªæŒ‡æ¨™æ¯”ä¾‹
        relevance_ratio = metrics['relevance_count'] / metrics['total_valid_rounds']
        concreteness_ratio = metrics['concreteness_count'] / metrics['total_valid_rounds']
        constructive_ratio = metrics['constructive_count'] / metrics['total_valid_rounds']
        
        # æ ¹æ“šå“è³ªæŒ‡æ¨™å½±éŸ¿æˆç¸¾ï¼ˆæ¨¡æ“¬åˆç†çš„ç›¸é—œæ€§ï¼‰
        quality_score = (relevance_ratio * 0.3 + concreteness_ratio * 0.4 + constructive_ratio * 0.3)
        
        # åŸºç¤æˆç¸¾ + å“è³ªå½±éŸ¿ + éš¨æ©Ÿè®Šç•°
        base_score = 70 + quality_score * 25 + np.random.normal(0, 5)
        
        scores_data[student] = {
            'æœŸä¸­': max(50, min(100, base_score + np.random.normal(0, 3))),
            'æœŸæœ«': max(50, min(100, base_score + np.random.normal(0, 3))),
            'å­¸æœŸ': max(50, min(100, base_score + np.random.normal(0, 2)))
        }
    
    return scores_data

def create_correlation_analysis():
    """å‰µå»ºå“è³ªæŒ‡æ¨™èˆ‡æˆç¸¾çš„ç›¸é—œæ€§åˆ†æ"""
    
    # è¼‰å…¥è³‡æ–™
    student_metrics = load_student_data()
    scores_data = generate_mock_scores(student_metrics)
    
    # æº–å‚™åˆ†æè³‡æ–™
    analysis_data = []
    
    for student, metrics in student_metrics.items():
        if student in scores_data and metrics['total_valid_rounds'] > 0:
            total_rounds = metrics['total_valid_rounds']
            
            row = {
                'å­¸ç”Ÿ': student,
                'ç›¸é—œæ€§': metrics['relevance_count'] / total_rounds,
                'å…·é«”æ€§': metrics['concreteness_count'] / total_rounds,
                'å»ºè¨­æ€§': metrics['constructive_count'] / total_rounds,
                'æœŸä¸­': scores_data[student]['æœŸä¸­'],
                'æœŸæœ«': scores_data[student]['æœŸæœ«'],
                'å­¸æœŸ': scores_data[student]['å­¸æœŸ']
            }
            analysis_data.append(row)
    
    df = pd.DataFrame(analysis_data)
    
    # è¨ˆç®—ç›¸é—œä¿‚æ•¸çŸ©é™£
    correlation_cols = ['ç›¸é—œæ€§', 'å…·é«”æ€§', 'å»ºè¨­æ€§', 'æœŸä¸­', 'æœŸæœ«', 'å­¸æœŸ']
    correlation_matrix = df[correlation_cols].corr()
    
    return df, correlation_matrix

def create_unified_heatmap(correlation_matrix):
    """å‰µå»ºçµ±ä¸€è‰²å½©çš„ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ–"""
    
    plt.figure(figsize=(10, 8))
    
    # å‰µå»ºè‡ªå®šç¾©ç´…è—é…è‰² - ç´…è‰²è¡¨ç¤ºæ­£ç›¸é—œï¼Œè—è‰²è¡¨ç¤ºè² ç›¸é—œ
    colors = ['#1e40af', '#3b82f6', '#60a5fa', '#93c5fd', '#f1f5f9', 
              '#fecaca', '#f87171', '#ef4444', '#dc2626', '#b91c1c']
    
    from matplotlib.colors import LinearSegmentedColormap
    custom_cmap = LinearSegmentedColormap.from_list('custom_rdbu', colors, N=256)
    
    # ç¹ªè£½ç†±åŠ›åœ–
    ax = sns.heatmap(
        correlation_matrix,
        annot=True,
        cmap=custom_cmap,
        center=0,
        square=True,
        fmt='.3f',
        cbar_kws={'shrink': 0.8, 'label': 'ç›¸é—œä¿‚æ•¸'},
        linewidths=0.5,
        vmin=-1,
        vmax=1,
        annot_kws={'size': 14, 'weight': 'bold'},
        xticklabels=True,
        yticklabels=True
    )
    
    # è¨­å®šæ¨™é¡Œå’Œæ¨™ç±¤
    plt.title('å“è³ªæŒ‡æ¨™èˆ‡æˆç¸¾ç›¸é—œä¿‚æ•¸çŸ©é™£', fontsize=18, pad=20, weight='bold')
    plt.xticks(rotation=0, ha='center', fontsize=14)
    plt.yticks(rotation=0, fontsize=14)
    
    # æ·»åŠ è‰²å½©èªªæ˜
    plt.figtext(0.02, 0.02, 'ğŸ”µ è² ç›¸é—œ (è—è‰²)     ğŸ”´ æ­£ç›¸é—œ (ç´…è‰²)     é¡è‰²æ·±åº¦è¡¨ç¤ºç›¸é—œæ€§å¼·åº¦', 
                fontsize=12, ha='left', weight='bold')
    
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.15)
    
    return plt

def generate_correlation_report():
    """ç”Ÿæˆå®Œæ•´çš„ç›¸é—œä¿‚æ•¸åˆ†æå ±å‘Š"""
    
    print("é–‹å§‹åˆ†æå“è³ªæŒ‡æ¨™èˆ‡æˆç¸¾çš„ç›¸é—œæ€§...")
    
    # å‰µå»ºç›¸é—œæ€§åˆ†æ
    df, correlation_matrix = create_correlation_analysis()
    
    if df.empty:
        print("ç„¡æ³•è¼‰å…¥æœ‰æ•ˆè³‡æ–™")
        return
    
    print(f"åˆ†æå­¸ç”Ÿæ•¸é‡: {len(df)}")
    print("ç›¸é—œä¿‚æ•¸çŸ©é™£:")
    print(correlation_matrix)
    
    # å‰µå»ºä¸¦å„²å­˜ç†±åŠ›åœ–
    plt_obj = create_unified_heatmap(correlation_matrix)
    
    output_path = os.path.join(BASE_DIR, 'static', 'quality_score_correlation.png')
    plt_obj.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"ç†±åŠ›åœ–å·²å„²å­˜è‡³: {output_path}")
    
    # ç”ŸæˆJSONè³‡æ–™ä¾›å‰ç«¯ä½¿ç”¨
    result_data = {
        'correlation_matrix': correlation_matrix.to_dict(),
        'student_count': len(df),
        'variables': ['ç›¸é—œæ€§', 'å…·é«”æ€§', 'å»ºè¨­æ€§', 'æœŸä¸­', 'æœŸæœ«', 'å­¸æœŸ']
    }
    
    json_path = os.path.join(BASE_DIR, 'static', 'correlation_data.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    
    print(f"ç›¸é—œæ€§è³‡æ–™å·²å„²å­˜è‡³: {json_path}")
    
    plt_obj.show()
    
    return df, correlation_matrix

if __name__ == "__main__":
    generate_correlation_report()
